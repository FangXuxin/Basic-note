# 操作系统

## 一、计算机系统概述
### 1.1 操作系统的基本概念

#### 1.1.1 OS的概念
计算机系统自下而上分为4部分：**硬件、操作系统、应用程序、用户**
<div align="center"><img src='figure\计算机层次结构.png' width=40%/></div>

**操作系统（Operating System，OS）** 是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织和调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境，它是计算机系统中最基本的 **系统软件**。

<div align="center"><img src='figure\命令接口.png' width=50%/></div>

**命令接口**：联机控制、脱机控制方式 **（直接使用）**

> 联机命令接口(交互式)->实时读取输入命令，并进行执行
> 
> 脱机命令接口(批处理)->写一份命令书，系统逐条解析

**程序接口**：有一组**系统调用**组成。典型为图形用户界面（GUI）图形接口 **（间接使用）**

#### 1.1.2 OS的特征
操作系统的特征：**并发、共享、虚拟、异步**（其中**并发**和**共享**为两个最基本特征）

1.并发（Concurrence）
> 两个或多个事件在**同一时间间隔**内发生

2.共享（Sharing）
> **资源共享**，指系统中的资源可**供内存中多个并发执行的进程共同使用**
> 
> **1.互斥共享** 某些资源，如打印机，可供多进程使用但是同一时间内只允许一个进程进行访问
> 
> **2.同时访问** 允许一个时间段内由多个进程“同时”进行访问

3.虚拟（Virtual）
> 指把一个物理上的实体变为若干逻辑上的对应物。用于实现虚拟的技术为虚拟技术，例如如下
>
> **1. 虚拟处理器**
利用多道程序设计技术把物理上的CPU虚拟为多个逻辑上的CPU
>
> **2. 虚拟内存**
将计算机的物理存储器变为虚拟存储器
>
> **3. 虚拟外部设备**
虚拟设备技术，将一台物理I/O设备虚拟为多台逻辑上的I/O设备，允许多个用户同时访问。 
（临界资源）单用户设备->共享设备

4.异步（Asynchronism）
> 允许多个程序并发执行，但每道程序走走停停，以不可知的速度向前推进。操作系统必须保证异步执行的结果都相同

#### 1.1.3 OS的功能
操作系统的功能：**处理机管理、存储管理、设备管理、文件管理**

1.处理机管理
> 进程管理，包括进程控制、进程同步、进程通信、思索处理、处理机调度

2.存储管理
> 内存分配与回收、地址映射、内存保护与共享、内存扩充

3.设备管理
> 完成用户的I/O请求，包括缓冲管理、设备分配、设备处理和虚拟设备

4.文件管理
>  文件存储空间的管理、目录管理、文件读写管理和保护

### 1.2 操作系统运行环境和结构

<div align="center"><img src='figure\OS机制和结构.png'/></div>

#### 1.2.1 OS运行机制

两种指令：**特权指令、非特权指令**
> 特权指令不允许用户使用（如内存清零指令）

两种处理机状态：**核心态、用户态** （用 **程序状态字** 寄存器（PSW）中某标志位表示，0 为用户态，1 为核心态）
> 用户态（**目态**）：此时CPU只能执行非特权指令
> 
> 核心态（**管态**）：此时CPU可以执行特权指令和非特权指令

两种程序：**内核程序、应用程序**
> 内核程序：内核程序是系统的管理者，既可以执行特权指令，也可以执行非特权指令，运行在核心态
> 
> 应用程序：为了保证系统安全运行，普通应用程序只能执行非特权指令，运行在用户态


#### 1.2.2 OS内核
<div align="center"><img src='figure\层级结构.png'/></div>

**内核**是计算机上配置的底层**软件**，是操作系统最基本、最核心的部分。

实现操作系统内核功能的程序为**内核程序**。
<div align="center"><img src='figure\内核.png'/></div>

**时钟管理**
> 实现计时功能

**中断处理**
> 负责实现中断机制

**原语**
> 原语是一种特殊的程序，处于操作系统最底层，是最接近硬件的部分。其运行具有原子性———运行只能一气呵成，不可终端。运行时间较短、调用频繁。

**对系统资源进行管理的功能：**
- 进程管理
- 存储器管理
- 设备管理


#### 1.2.3 OS体系结构

**不同的内核体系结构：**
> **大内核**: 将操作系统的重要功能模块都作为系统内核，运行在核心态
> 
> 优点：高性能
> 
> 缺点：内核代码庞大，结构混乱，难以维护

> **微内核**: 只把基本的功能保留在内核
> 
> 优点：内核功能少，结构清晰，方便维护
> 
> 缺点：需要频繁地在核心态和用户态之间切换，性能低

### 1.3 中断和异常

#### 1.3.1 中断的概念和作用

**本质** ：发生中断意味着需要操作系统介入，开展管理工作

1. 当中断发生时，CPU立即进入**核心态**
2. 当中断发生后，**当前进程暂停**，并由操作系统**内核对中断进行处理**
3. 对于不同的中断信号，会进行不同的处理

**用户态 -> 核心态**：中断，且中断时唯一途径

**核心态 -> 用户态**：执行一个特权指令，将程序状态字（PSW）标志为用户态

#### 1.3.2 中断的分类

<div align="center"><img src='figure\中断分类.png' width=60%/></div>

<div align="center"><img src='figure\中断分类2.png' width=80%/></div>


#### 1.3.3 中断的处理过程

**外中断的处理过程**：

**Step1**：执行完每个指令后，CPU要检查当前是否有外部中断信号

**Step2**：如果有，则需要保存被中断程序的CPU环境（如程序状态字PSW、程序计数器PC、各种通用寄存器）

**Step3**：根据中断信号转入相应的中断处理程序

**Step4**：恢复原进程的CPU环境并退出中断，返回原程序继续执行

### 1.4 系统调用

<div align="center"><img src='figure\系统调用.png' width=60%/></div>

#### 1.4.1 系统调用定义及作用

**系统调用**是操作系统提供给应用程序（程序员/编程人员）使用的**接口**，可以理解为一种可**供应用程序调用的特殊函数**，应用程序可以发出系统调用请求来获得操作系统的服务

**作用**：与资源相关的操作，通过系统调用，统一由操作系统带为完成，以此**保证系统的稳定性和安全性**。

<div align="center"><img src='figure\系统调用1.png' width=80%/></div>

#### 1.4.2 系统调用和库函数的区别

<div align="center"><img src='figure\系统调用2.png' width=50%/></div>

应用程序可以通过汇编语言直接进行系统调用，现在可以通过高级语言提供的库函数来进行系统调用

#### 1.4.3 系统调用背后的过程

<div align="center"><img src='figure\系统调用3.png' width=%/></div>

传递系统调用的参数 -> 执行陷入指令（**用户态**）-> 执行系统调用相应服务程序（**核心态**）-> 返回用户程序

**系统调用会使处理器从用户态进入核心态。**

## 二、进程与线程

### 2.1 进程

#### 2.1.1 进程的定义、组成、组织方式、特征

**程序**：一个指令序列

不同角度进程的典型定义：

1. 进程是程序的一次**执行过程**。
2. 进程是一个程序及其数据在处理机上顺序执行时所**发生的活动**。
3. 进程是具有独立功能的程序在数据集合上**运行的过程**，它是系统进行资源分配和调度的一个独立单位。

综上，进程可定义为：
> **进程**是进程实体的运行过程，是系统进行**资源分配**和**调度**的一个独立单位。

<div align="center"><img src='figure\进程的组成1.png' width=70%/></div>

**进程实体**：程序段、数据段、PCB（进程存在的唯一标志！）

<div align="center"><img src='figure\进程的组成.png' width=70%/></div>

**进程的组织方式**：
>**链接方式**：
>
> 按照进程状态将PCB分为多个队列；
>
> 操作系统持有指向各个队列的指针；
><div align="center"><img src='figure\链接方式.png' width=50%/></div>
>
>**索引方式**：
>
> 根据进程状态的而不同，建立几张索引表；
>
> 操作系统持有指向各个索引表的指针；
><div align="center"><img src='figure\索引方式.png' width=50%/></div>
 
**进程的特征**：
> **动态性**：进程是程序的一次执行过程，是动态地产生、变化和消亡的。（进程最基本的特征）
> 
> **并发性**：内存中有多个进程实体，各进程可并发执行。
> 
> **独立性**：进程是能独立运行、独立获得资源、独立接受调度的基本单位。（进程是资源分配、接受调度的基本单位）
> 
> **异步性**：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制”来解决异步问题。（异步性会导致并发程序执行的不确定性）
> 
> **结构性**：每个进程都会配置一个PCB。结构上看，进程由程序段、数据段、PCB组成
<!-- <div align="center"><img src='figure\进程的特征.png' width=80%/></div> -->

#### 2.1.2 进程的状态与转换
<div align="center"><img src='figure\进程的状态及转换.png' width=60%/></div>


进程的**三种基本状态**：

> **运行态（Running）**：占有CPU，并**在CPU上运行**。——单核处理机环境下，每个时刻最多只有一个进程处于运行态（双核可以有两个）
> 
> **就绪态（Ready）**：已经具备运行条件，但由于没有空闲CPU，而暂时不能运行。——经常已经拥有了除处理机外所有需要的资源，即：**万事具备，只欠CPU**
> 
> **阻塞态（Waiting/Blocked，又称：等待态）**：因等待某一事件而暂时不能运行。


另外**两种状态**：
>**创建态（New，新建态）**：进程正在被创建，操作系统为进程分配资源、初始化PCB
>
>**终止态（Terminated，结束态）**:进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB

**多种进程转换**

<div align="center"><img src='figure\进程状态的转换.png' width=80%/></div>

<div align="center"><img src='figure\七状态模型.png' width=80%/></div>

#### 2.1.3 进程控制

<div align="center"><img src='figure\进程控制.png' width=60%/></div>

**进程控制**定义：

> 对系统中的所有进程实施有效的管理，实现进程状态的转换

**用原语实现进程控制**。
> 原语的**特点**是执行期间**不允许中断**，只能一起呵成。
><div align="left"><img src='figure\进程控制1.png' width=35%/></div>
>
> 采用 “**开中断**指令” 和 “**关中断**指令” 实现
>
> 显然，**开/关中断指令**的权限非常大，必然是只允许在**核心态**下执行的**特权指令**。

**进程控制相关原语**：
> 1. **更新PCB中的信息**（如**修改进程状态标志**、将运行**环境保存**到PCB、从PCB**恢复运行环境**）
> 
>       a.所有进程的控制原语一定都会修改进程状态标志
> 
>       b.剥夺当前运行进程的CPU使用权必然需要保存其运行环境
> 
>       c.某进程开始运行前必然要恢复其运行环境
> 2. 将PCB**安插**进合适的**队列**
> 3. **分配/回收资源**
---
<div align="left"><img src='figure\进程创建.png' width=%/></div>

---
<div align="left"><img src='figure\进程终止.png' width=%/></div>

---
<div align="left"><img src='figure\进程阻塞.png' width=%/></div>

---
<div align="left"><img src='figure\进程切换.png' width=%/></div>

#### 2.1.4 进程通信
<div align="center"><img src='figure\进程通信.png' width=80%/></div>

进程之间的信息交换
1. **共享存储**

通信进程间存在一块共享空间，通过使用同步互斥工具（如P、V操作）来对共享空间进行读/写操作。

共享存储分为：基于数据结构的共享（低级）；基于存储区的共享（高级）

操作系统只为共享提供存储空间和同步互斥工具，数据交换则是由用户自己的读/写指令完成

2. **消息传递**

消息传递系统中，进程间的数据交换以格式化的消息（Message）为单位。若进程间不存在共享空间，则必须利用消息传递实现进程通信。（通过系统提供的发送消息和接收消息两个原语进行数据交换）

    1）直接通信方式：直接发给接受进程。将其挂在的消息缓存队列上

    2）间接通信方式：发送给某个中间实体，接受进程从中间实体取得消息，中间实体一般为“信箱”

3. **管道通信**

消息传递的特殊方式。管道连接一个读进程和一个写进程，其共享文件为pipe文件。

管道机制必须提供三方面的协调能力：互斥、同步和确定对方的存在。

管道通信时共享存储的优化和发展（半双工通信）


### 2.2 线程概念和多线程模型

#### 2.2.1 线程的概念

线程是一个基本的CPU执行单元，也是程序执行的最小单位，称“轻量级进程”。

引入线程后，提高了程序的并发度。

#### 2.2.2 线程与进程的比较
1. **调度**——引入线程后，线程是调度的基本单位。单个进程中线程的切换不会引起进程切换，不同进程中线程切换会引起进程切换
2. **并发性**——都有并发性
3. **资源**——进程是系统中拥有资源的基本单位，线程不拥有系统资源，但是可以访问对应进程的资源
4. **独立性**——进程间共享通过共享空间，而同一进程的线程间共享进程的地址空间和资源
5. **系统开销**——进程相较于线程操作时系统开销大
6. **支持多处理机系统**——多线程进程能够线程分配到多个处理机上

#### 2.2.3 线程的属性
- 线程是处理机调度的单位
- 多CPU计算机中，各个线程可占用不同的CPU
- 各线程都有一个线程ID、线程控制块（TCB）
- 线程也有就绪、阻塞、运行三种基本状态
- 线程几乎不拥有系统资源
- 同一进程的不同线程间共享进程的资源
- 由于共享内存地址空间，同进程中的线程间通信甚至无需系统干预
- 同一进程中的线程切换，不会引起进程切换
- 不同进程中的线程切换，会引起进程切换
- 切换同进程内的线程，系统开销很小
- 切换进程系统开销大


#### 2.2.4 线程的实现方式

**用户级线程**：由应用程序通过线程库实现。对用户透明对操作系统不透明。进程切换在**用户态**下可完成。
<div align="left"><img src='figure\用户级.png' width=40%/></div>

**内核级线程**：由操作系统内核完成。内核级线程切换在**核心态**完成。操作系统可见（**处理机分配的单位**）


#### 2.2.5 多线程模型

**多对一模型**：多个用户级线程映射到一个内核级线程上。
> **优点**：切换在用户态就能完成，系统开销小，效率高
>
> **缺点**：当一个用户级线程被阻塞后，整个进程会被阻塞，并发度不高。多个线程不可在多核处理机运行

**一对一模型**：一个用户级对应一个内核级线程。
> **优点**：当一个线程阻塞后，别的线程还能继续运行，并发能力强，多线程可在多核处理机上并行执行
>
> **缺点**：一个进程会占用多个内核级线程，线程切换在核心态，管理成本高，开销大

**多对多模型**：$n$个用户级线程映射到$m$个内核级线程$(n\ge m)$。每个用户进程对应$m$个内核级线程
> 克服了多对一并发度不高的缺点，又克服了一对一中进程占用太多内核级线程的缺点。

### 2.3 处理机调度

#### 2.3.1 处理机调度的概念和层次
<div align="left"><img src='figure\处理机调度.png' width=%/></div>

**处理机调度概念**：从就绪队列中按照**一定的算法选择一个进程**分配处理机。

**处理机调度的三个层次**
> **高级调度(作业调度)**：按一定的调度算法**从外存上处于后备队列的作业中挑选一个**（或多个）作业，**给他们分配内存等必要资源**，并分配PCB使它们获得竞争处理机的权利。（只一次）

> **中级调度(内存调度)**：**为了提升内存利用率和系统吞吐量**。**将暂时不能运行的进程调至外存等待**，该状态为**挂起状态**。PCB不会一起调到外存，其会常驻内存中，记录进程在外存中存放位置，进程状态等信息。（可多次）

> **低级调度(进程调度)**：按照某种调度算法，**从就绪队列中选取一个进程分配处理机**。**低级调度是最基本的一种调度，频率很高，一般几十毫秒一次。**

<div align="center"><img src='figure\七状态模型.png' width=80%/></div>

#### 2.3.2 进程调度的时机、切换与过程、方式

**进程调度（低级调度）时机**：
> **需要进行进程切换**的情况：
> - 进程**主动放弃**处理机
>   - 进程正常终止
>   - 运行过程中异常终止
>   - 进程主动请求阻塞（如，等待I/O） 
> - 进程**被动放弃**处理机
>   - 进程分配的时间片用完
>   - 有更紧急的事需处理（如，I/O中断）
>   - 有更高优先级的进程进入就绪队列

> **不能进行进程切换**的情况：
> - 在**处理中断的过程中**
> - 进程在**操作系统内核程序临界区**中 **-->** 见下临界区解读
> - 在**原子操作**过程中

> **临界资源**：一个时间段的内只允许一个进程使用的资源。各进程需要**互斥**地访问临界资源
> 
> **临界区**：访问临界资源的代码
> 
> **内核程序临界区**：一般用来访问某种**内核数据结构**的，如，就绪队列（有各就绪的PCB组成）
> <div align="center"><img src='figure\临界区.png' width=40%/></div>
> 该种情况下，如果未退出内核程序临界区则表示还在就绪队列未解锁，而进程调度需要访问就绪队列，此时无法进行进程调度。

**进程调度的方式**：
> **非剥夺调度方式（非抢占方式）**：只允许进程主动放弃处理机。如果有更紧急的任务到，当前进程仍然会继续使用处理机。
> 
> **剥夺调度方式（抢占式）**：当有更紧急的进程到达时，立即暂停正在执行的进程，将处理机分配给紧急进程。


#### 2.3.3 调度算法及评价指标

**评价指标**：
> **CPU利用率**：指CPU“忙碌”的时间占总时间的比例。$利用率=\frac{忙碌时间}{总时间}$
> 
> **系统吞吐量**：单位时间完成作业的数量$系统吞吐量=\frac{完成作业数}{总时间}$
> 
> **周转时间**：从昨夜被提交到系统开始至完成的时间间隔。$周转时间：作业完成时间-作业提交时间$，$平均周转时间=\frac{各周转时间之和}{作业数}$，$带权周转时间=\frac{周转时间}{实际运行时间}$，$平均带权周转时间=\frac{各作业带权周转时间之和}{作业数}$
> 
> **等待时间**：进程/作业处于等待处理机状态时间之和。
> 
> **响应时间**：提交请求到首次产生响应所用时间。

**调度算法**
- **先来先服务（FCFS）**
  > **算法思想**:“公平”角度考虑
  >
  > **算法规则**：按照作业/进程到达的先后顺序进行服务
  >
  > **进程调度**：用于作业调度时，考虑的是哪个作业先到达后备队列；用于进程调度时，考虑哪个进程先到达就绪队列。
  >
  > **是否抢占**：非抢占式算法
  >
  > **优点**：公平、算法实现简单
  >
  > **缺点**：排在长作业（进程）后面的短作业需要等待很长时间，带权周转时间很大。对长作业有利，对短作业不利。
  >
  > **是否会导致饥饿**：不会
- **短作业优先（SJF）**
  > **算法思想**: 追求最少的平均等待时间，最少的平均周转世时间、最少的平均带权时间。
  >
  > **算法规则**：服务最短的作业/进程优先得到服务
  >
  > **进程调度**：用于进程调度时成为“短进程有限（SPF）”算法
  >
  > **是否抢占**：非抢占式。抢占式版本——最短剩余时间优先算法（SRTN）
  >
  > **优点**：“最短的”平均等待时间、平均周转时间
  >
  > **缺点**：不公平。对短作业有利对长作业不利。
  >
  > **是否会导致饥饿**：会。如果有源源不断的短作业到来，那么可能会“饿死”

  > **最短剩余时间优先算法（SRTN）**:每次作业到来都比较当前的需运行时间
  > <div align="left"><img src='figure\短作业优先.png' width=75%/></div>
- **高响应比优先（HRRN）**
  > **算法思想**：综合考虑作业/进程的等待时间和要求服务时间
  >
  > **算法规则**：在每次调度时先计算各个作业/进程的响应比，选择响应比最高的服务 $响应比=\frac{等待时间+要求服务时间}{要求服务时间}$
  >
  > **进程调度**：进程/作业都可用
  >
  > **是否抢占**：非抢占式
  >
  > **优缺点**：综合考虑了等待时间和运行时间
  >
  > **是否会导致饥饿**：不会

- **时间片轮转（RR，Round-Robin）**
  > **算法思想**：公平地、轮流地为各个进程服务。
  >
  > **算法规则**：按照各进程到达就绪队列的顺序，轮流让各个进程执行一个**时间片**。若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列队尾。
  >
  > **进程调度**：用于进程调度（只有作业放入进程建立进程后，才能被分配处理机时间片）
  >
  > **是否抢占**：**抢占式**。如果进程未能在时间片内运行完，则被剥夺处理机。由时钟装置发出**时钟中断**来通知CPU时间片到达
  >
  > **优点**： 公平、响应快，适用于分时操作系统
  >
  > **缺点**：由于高频进程切换，因此有一定开销，且不区分任务紧急程度。
  >
  > **是否会导致饥饿**：不会

- **优先级调度算法**
  > **算法思想**：处理紧急任务地能力需要提升
  >
  > **算法规则**：调度时选择优先级最高地作业/进程
  >
  > **进程调度**：作业/进程都可用。甚至还会用于I/O调度
  >
  > **是否抢占**：抢占、非抢占都有。抢占式还需考虑就绪队列的实时变化
  >
  > **优点**：用优先级区分紧急程度、重要程度，适用于实时操作系统。
  >
  > **缺点**：若一直有高优先级进程到来，会导致饥饿
  >
  > **是否会导致饥饿**：会

  > **补充**：
  > <div align="left"><img src='figure\优先级调度算法.png' width=75%/></div>

- **多级反馈队列调度算法**
  > **算法思想**：对其他调度算法的折中权衡
  >
  > **算法规则**：
  >
  >   1.设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
  >
  >   2.新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进程进入下一级队列队尾。如果此时已经是在最下级的队列，则重新放回该队列队尾
  >
  >   3.只有第k级队列为空时，才会为k+1级队头的进程分配时间片
  >
  > **进程调度**：用于进程调度
  >
  > **是否抢占**：抢占式的算法。在k级队列的进程运行过程中，若更上级的队列(1~k-1级)中进入了一个新进程，则由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，原来运行的进程放回k级队列对尾
  >
  > **优缺点**：以上算法的优点
  >
  > **是否会导致饥饿**：会

### 2.4 进程同步、互斥

#### 2.4.1 进程同步互斥概念
**进程同步**：同步亦称直接制约关系，它是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而产生的制约关系。进程间的直接制约关系就是源于它们之间的相互合作。

**进程互斥**：互斥，亦称间接制约关系。进程互斥指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源之后,另一个进程才能去访问临界资源。

<div align="center"><img src='figure\进程同步互斥.png' width=75%/></div>

#### 2.4.2 进程互斥的软件实现方法

**单标志法:**
> <div align="left"><img src='figure\单标志法.png' width=75%/></div>

**双标志先检查法：**
> <div align="left"><img src='figure\单标志法.png' width=75%/></div>

**双标志后检查法：**

> <div align="left"><img src='figure\单标志法.png' width=75%/></div>

**Peterson法：**
> <div align="left"><img src='figure\单标志法.png' width=75%/></div>

#### 2.4.2 进程互斥的硬件实现方法

**中断屏蔽方法：**
> 利用“开/关中断指令”实现(与原语的实现思想相同，即在某进程开始访问临界区到结束访问为止都不允许被中断，也就不能发生进程切换，因此也不可能发生两个同时访问临界区的情况)
> ```c
> ...
> 关中断;   //关中断后即不允许当前进程被中断，也必然不会发生进程切换
> 临界区;
> 开中断;   //直到当前进程访问完临界区，再执行开中断指令，才有可能有别的进程上处理机并访问临界区
> ...
> ```
> **优点**:简单、高效
> 
> **缺点**:不适用于多处理机;只适用于操作系统内核进程，不适用于用户进程(因为开/关中断指令只能运行在内核态，这组指令如果能让用户随意使用会很危险)

**TestAndSet指令**

**Swap指令**

#### 2.4.3 信号量机制

**信号量**：信号量是一个变量，用来**表示系统中某种资源的数量**。整形、记录型

**一对原语**：`wait(S)`和`signal(s)`原语，可以理解为自己写的函数，函数名为`wait`和`signal`，信号量`S`表示传入参数。`wait`和`signal`原语常简称`P`、`V`操作，写`P(S)`、`V(S)`

#### 2.4.4 信号量机制实现进程互斥、同步、前驱

**信号量实现互斥**
> 1. 分析并发进程的关键活动
> 2. 设置互斥信号量`mutex`，初值为`1`
> 3. 在临界区之前执行`P(mutex)`
> 4. 在临界区之后执行`V(mutex)`
> 
> 注意:对**不同的临界资源**需要**设置不同的互斥信号量**。**P、V操作必须成对出现**。缺少`P(mutex)`就不能保证临界资源的互斥访问。缺少`V(mutex)`会导致资源永不被释放，等待进程永不被唤醒。
 ```c
 /*信号机制实现互斥*/
 semaphore mutex=1; // 初始化信号量
 P1(){
 ...
 P(mutex); //使用临界资源前需要加锁
 临界区代码段...
 V(mutex); //使用临界资源后需要解锁
 ...
 }
 P2(){
 P(mutex);
 临界区代码段... 
 V(mutex);
 ...
 }
 ```
**信号量实现同步**

 2.3.5-2.3.11
补

### 2.5 死锁

#### 2.5.1 死锁的概念
**死锁**：进程因争资源而造成的一种**互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进**的现象

**死锁发生的必要条件**：
> **互斥条件**:只有对**必须互斥使用的资源的争抢**才会导致死锁(如哲学家的筷子、打印机设备)。像内存、扬声器这样可以同时让多个进程使用的资源是不会导致死锁的(因为进程不用阻塞等待这种资源)。
> 
> **不剥夺条件**:进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。
>
>**请求和保持条件**:进程**已经保持了至少一个资源**，**但又提出了新的资源请求**，而该资源又被其他进程占有，此时请求进程被阻塞，**但又对自己已有的资源保持不放**。
>
>**循环等待条件**:存在一种进程**资源的循环等待链**，链中的每一个进程已获得的资源同时被下一个进程所请求。
>
>**注意！发生死锁时一定有循环等待，但是发生循环等待时未必死锁**(循环等待是死锁的必要不充分条件)如果同类资源数大于1，则即使有循环等待，也未必发生死锁。但如果系统中每类资源都只有一个，那循环等待就是死锁的充分必要条件了。

**什么时候会发生死锁**——对不可剥夺资源的不合理分配，可能导致死锁。
- 对系统资源的竞争。
  > 各进程对不可剥夺的资源(如打印机)的竞争可能引起死锁，对可剥夺的资源(CPU)的竞争是不会引起死锁的。
- 进程推进顺序非法。
  > 请求和释放资源的顺序不当，也同样会导致死锁。例如，并发执行的进程P1、P2分别申请并占有了资源R1、R2，之后进程P1又紧接着申请资源R2，而进程P2又申请资源R1,两者会因为申请的资源被对方占有而阻塞，从而发生死锁。
- 信号量的使用不当。
  > 如生产者-消费者问题中，如果实现互斥的P操作在实现同步的P操作之前，就有可能导致死锁。(可以把互斥信号量、同步信号量也看做是一种抽象的系统资源)


**死锁的处理策略**
1. 预防死锁。破坏死锁产生的四个必要条件中的一个或几个。
2. 避免死锁。用某种方法防止系统进入不安全状态，从而避免死锁( 银行家算法)
3. 死锁的检测和解除。允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措施解除死锁。

#### 2.5.2 预防死锁
破坏死锁产生的四个必要条件中的一个或几个。

**破坏互斥条件**
> 如果把只能互斥使用的**资源改造为允许共享使用**，则系统不会进入死锁状态。比如: **SPOOLing技术**。操作系统可以采用SPOOLing技术把独占设备在逻辑上改造成共享设备。
> 
> **缺点**：并不是所有的资源都可以改造成可共享使用的资源。并且为了系统安全，很多地方还必须保护这种互斥性。因此，很多时候都无法破坏互斥条件。

**破坏不剥夺条件**
> **方案一**:**当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请**。也就是说，即使某些资源尚未使用完，也需要主动释放，从而破坏了不可剥夺条件。
> 
> **方案二**:**当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺**。这种方式一般需要考虑各进程的优先级(比如:剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用)
>
> **缺点**:
> 1. 实现起来比较复杂。
> 2. 释放已获得的资源可能造成前一阶段工作的失效。因此这种方法-一般只适用于易保存和恢复状态的资源，如CPU。
> 3. 反复地申请和释放资源会增加系统开销，降低系统吞吐量。
> 4. 若采用方案一，意味着只要暂时得不到某个资源，之前获得的那些资源就都需要放弃，以后再重新申请。如果一直发生这样的情况，就会导致进程饥饿。

**破坏请求和保持条件**
> 可以采用**静态分配方法**，即**进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前,不让它投入运行**。一旦投入运行后，这些资源就一直归它所有， 该进程就不会再请求别的任何资源了。
> 
> **缺点**:有些资源可能只需要用很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，**资源利用率极低**。另外，该策略也有**可能导致某些进程饥饿**。

**破坏循环等待条件**
> 可采用**顺序资源分配法**。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源,同类资源(即编号相同的资源)一次申请完。
> 
> **原理分析**: 一个进程只有已占有小编号的资源时，才有资格申请更大编号的资源。按此规则，已持有大编号资源的进程不可能逆向地回来申请小编号的资源，从而就不会产生循环等待的现象。
>
> **缺点**:
> 1. 不方便增加新的设备，因为可能需要重新分配所有的编号;
> 2. 进程实际使用资源的顺序可能和编号递增顺序不一致，会导致资源浪费;
> 3. 必须按规定次序申请资源，用户编程麻烦。

#### 2.5.3 避免死锁
**安全序列**：指如果**系统按照这种序列分配资源，则每个进程都能顺利完成**。只要能找出一个安全序列，系统就是安全状态。
> 当然，安全序列可能有多个。如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后可能所有进程都无法顺利的执行下去。当然，如果有进程提前归还了一些资源，那系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。**如果系统处于安全状态，就一定不会发生死锁**。如果**系统进入不安全状态，就可能发生死锁**(处于不安全状态未必就是发生了死锁，但发生死锁时一定是在不安全状态)


**银行家算法**
> **核心思想**:在进程提出资源申请时，先预判此次分配是否会导致系统进入不安全状态。如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。


<div align="center"><img src="figure\银行家算法1.png" width=55%/></div>
<center class="half">
    <img src="figure\银行家算法2.png" width=45%/>
    <img src="figure\银行家算法3.png" width=45%/>
</center>

<div align="center"><img src="figure\银行家算法4.png" width=85%/></div>

**数据结构:**
> 长度为$m$的一维数组`Available`表示还有多少可用资源$n×m$矩阵`Max`表示各进程对资源的最大需求数$n×m$矩阵`Allocation`表示已经给各进程分配了多少资源$Max-Allocation=Need$矩阵表示各进程最多还需要多少资源用长度为$m$的一位数组`Request`表示进程此次申请的各种资源数

**银行家算法步骤**:

①检查此次申请是否超过了之前声明的最大需求数

②检查此时系统剩余的可用资源是否还能满足这次请求

③试探着分配，更改各数据结构

④用安全性算法检查此次分配是否会导致系统进入不安全状态

**死锁检测算法**
<div align="center"><img src="figure\死锁检查.png" width=85%/></div>

>**检测死锁的算法**:
> 
>1)在资源分配图中，找出既不阻塞又不是孤点的进程Pi (即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。如下图中，R1没有空闲资源，R2有一个空闲资源。若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源)。消去它所有的请求边和分配变，使之称为孤立的结点。在下图中, P1是满足这一条件的进程结点，于是将P1的所有边消去。
>
>2)进程Pi所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在下图中，P2就满足这样的条件。根据1)中的方法进行一系列简化后，若能消去途中所有的边，则称该图是可完全简化的。
> <div align="center"><img src="figure\死锁.png" width=50%/></div>


> **解除死锁的主要方法有**:
> 1. **资源剥夺法**。挂起(暂时放到外存上)某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但是应防止被挂起的进程长时间得不到资源而饥饿。
> 2. **撤销进程法(或称终止进程法)**。强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大。因为有些进程可能已经运行了很长时间，已经接近结束了，一-旦被终止可谓功亏一篑， 以后还得从头再来。
> 3. **进程回退法**。让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点。

## 三、内存管理
### 3.1 内存和内存管理
#### 3.1.1 内存基础知识
**内存**：用于存放数据的硬件
**内存地址**：内存中存储单元编号，从0开始

> $2^{10}=1K$
> 
> $2^{20}=1M$
> 
> $2^{30}=1G$
> 
> $4G$ 表示 $4\times 2^{30}=2^{32}$ 故须 $32$ 位地址

#### 3.1.2 内存管理

**内存管理包括四点**
- **内存空间的分配与回收**
  > 连续分配管理方式
  > 1. 单一连续分配
  > 2. 固定分区分配
  > 3. 动态分区分配
  > 
  > 非连续分配方式
  > 1. 基本分页存储管理
  > 2. 基本分段存储管理
  > 3. 段页式存储管理
- **内存空间的扩充**
  > 1. 覆盖技术
  > 2. 交换技术
  > 3. 虚拟存储技术
- **地址转换**
  > **操作系统实现逻辑地址到物理地址的转换**
  >
  > 具体三种方式：
  > 1. **绝对装入**:编译器负责地址转换( 单道程序阶段，无操作系统)
  > 2. **可重定位装入**:装入程序负责地址转换(早期多道批处理阶段)
  > 3. **动态运行时装入**:运行时才进行地址转换(现代操作系统)
 
- **存储保护**
  > **保证各进程在自己的内存空间内运行，不会越界访问**
  >
  > 两种方式:
  > 1. 设置上下限寄存器
  > 2. 利用重定位寄存器、界地址寄存器进行判断

#### 3.1.3 内存空间的分配与回收

**连续分配管理方式**
> **单一连续分配**
> 
> 在单一连续分配方式中,内存被分为**系统区**和**用户区**。**系统区通常位于内存的低地址部分**，用于存放操作系统相关数据;用户区用于存放用户进程相关数据。**内存中只能有一道用户程序**，用户程序独占整个用户区空间。
> 
> **优点**:实现简单;无外部碎片;可以采用覆盖技术扩充内存;不一定需要采取内存保护(eg:早期的PC操作系统MS-DOS )
> 
> **缺点**:只能用于单用户、单任务的操作系统中;有内部碎片;存储器利用率极低。
> <div align="center"><img src="figure\单一连续分配.png" width=50%/></div>

> **固定分区分配**
> **分区大小相等**:缺乏灵活性，但是很适合用于用一台计算机控制多个相同对象的场合(比如:钢铁厂有$n$个相同的炼钢炉，就可把内存分为$n$个大小相等的区域存放$n$个炼钢炉控制程序)
>
> **分区大小不等**:增加了灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况进行划分(比如:划分多个小分区、适量中等分区、少量大分区)
>
> <div align="center"><img src="figure\固定分区.png" width=50%/></div>
> 
>操作系统需要建立一个数据结构 —— **分区说明表** ,来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始地址、状态(是否已分配)。
> <div align="center"><img src="figure\分区表.png" width=80%/></div>
> 
> 当某用户程序要装入内存时，由操作系统内核程序根据用户程序大小检索该表,从中找到**一个能满足大小的、未分配的分区**，将之分配给该程序，然后修改状态为“**已分配**”。
> 
> **优点**:实现简单，**无外部碎片**。
> 
> **缺点**: a. 当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能; b. **会产生内部碎片，内存利用率低**。


**动态分区分配**

> **动态分区分配**又称为**可变分区分配**。这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小**动态地建立分区**，并使**分区的大小正好适合进程的需要**。因此系统分区的大小和数目是可变的。(eg: 假设某计算机内存大小为64MB，系统区8MB，用户区共56 M...)
> <div align="center"><img src="figure\动态分区数据结构.png" width=80%/></div>
> 
> 动态分区分配**没有内部碎片**，但是**有外部碎片**。
> 
> **内部碎片**，分配给某进程的内存区域中，如果有些部分没有用上。
> 
> **外部碎片**，是指内存中的某些空闲分区由于太小而难以利用。
> 
> 如果内存中空闲空间的总和本来可以满足某进程的要求,但由于进程需要的是一整块连续的内存空间，因此这些“碎片”.不能满足进程的需求。可以通过紧凑(拼凑，Compaction) 技术来解决外部碎片。

> **动态分区分配算法** 
> 
> **首次适应算法(First Fit)** 
>> **算法思想**:每次都从低地址开始查找，找到第一个能满足大小的空闲分区。
>>   
>> **实现**:空闲分区**以地址递增的次序排列**。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。
> 
> **最佳适应算法(Best Fit)**
>> **算法思想**:由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。
>>
>> **如何实现**:空闲分区**按容量递增次序链接**。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。
>> 
>> **缺点**:每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种方法会产生很多的外部碎片。
>
> **最坏适应算法(Worst Fit)**
>> 又称**最大适应算法**(Largest Fit)
>>
>> **算法思想**:为了解决最佳适应算法的问题----即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。
>>
>> **如何实现**:空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。
>>
>>**缺点**:每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了。
>
> **邻近适应算法(Next Fit)**
>> **算法思想**:首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
>> 
>> **如何实现**:空闲分区以地址递增的顺序排列(可排成一个循环链表)。每次分配内存时**从上次查找结束的位置开始查找空闲分区链**(或空闲分区表)，找到大小能满足要求的第一个空闲分区。
 

**非连续分配方式**
> **基本分页存储管理的基本概念**
> 将内存空间分为一个个大小相等的分区(比如:每个分区4KB)，每个分区就是一个“页框”，或称“页帧”、“内存物理块”。每个页框有一个编号，即“页框号”(或者“内存块号”、“页帧号”、“物理块号”)页框号从0开始。
>
> 将用户进程的地址空间也分为与页框大小相等的一个个区域，称为“页”或“页面”。每个页面也有一个编号，即“页号”页号也是从0开始。(注:进程的最后一一个页面可能没有一个页框那么大。因此,页框不能太大，否则可能产生过大的内部碎片)
>
>操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。各个页面不必连续存放，也不必按先后顺序来，可以放到不相邻的各个页框中。
> <div align="center"><img src="figure\分页.png" width=35%/></div>
> <div align="center"><img src="figure\分页1.png" width=80%/></div>
> 
> 逻辑地址为80的内存单元:应该在1号页，该页在内存中的起始位置为450，逻辑地址为80的内存单元相对于该页的起始地址而言,偏移量”应该是30。实际物理地址=450+ 30 = 480
> 1. 要算出逻辑地址对应的页号
> 2. 要知道该页号对应页面在内存中的起始地址
> 3. 要算出逻辑地址在页面内的“偏移量"
> 4. 物理地址=页面始址+页内偏移量
> 
> **如何计算**:
> 
> `页号 = 逻辑地址 / 页面长度`
> 
> `页内偏移量 = 逻辑地址 % 页面长度`
> 
> 页面在内存中的起始位置:操作系统需要用某种数据结构记录进程各个页面的起始位置。
> <div align="center"><img src="figure\地址转换.png" width=80%/></div>
> 
> **页表**：记录进程页面和实际存放块之间的对应关系，一个进程对应一个页表，每个页表由“页号”和“块号”组成
> <div align="center"><img src="figure\页表.png" width=20%/></div>
>
> 初始地址：$X$ ，则第 $M$ 号页对应页表项内存地址为 $X + 3×M$


> **基本地址变换机构**可以**借助进程的页表将逻辑地址转换为物理地址**。通常会在系统中设置一个**页表寄存器(PTR)**，存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的始址和页表长度放在进程控制块(PCB)中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。
>
> CPU找寻指令（逻辑地址->物理地址）
> <div align="center"><img src="figure\计算机访问内存.png" width=80%/></div>

> **具有快表的地址变换机构**
>
> **局部性原理**
> - **时间局部性**:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)
> 
> - **空间局部性**:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的)
>
> **快表(TLB)**：快表，又称联想寄存器(TLB) ，是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。

> **基本分段存储管理**
> 
> **分段**:按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名(在低级语言中，程序员使用段名来编程)，每段从0开始编址
> 
> **内存分配规则**:以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻。





#### 3.1.4 内存空间扩充
**覆盖与交换**
> **覆盖技术**，用来解决“程序大小超过物理内存总和”的问题
>
> **覆盖技术的思想**:将程序分为多个段(多个模块)。常用的段常驻内存，不常用的段在需要时调入内存。
>
> 内存中分为一个“固定区”和若干个“覆盖区”。需要常驻内存的段放在“固定区”中，调入后就不再调出( 除非运行结束)不常用的段放在“覆盖区”需要用到时调入内存,用不到时调出内存
> <div align="center"><img src="figure\覆盖技术.png" width=80%/></div>
> 
> 必须由程序员**声明覆盖结构**，操作系统完成自动覆盖。
> 
> **缺点**:对用户不透明，增加了用户编程负担。覆盖技术只用于早期的操作系统中，现在已成为历史。

> **交换(对换)技术的设计思想**:内存空间紧张时，系统将内存中某些进程暂时换出外存，至挂起态，把外存中某些己具备运行条件的进程换入内存(进程在内存与磁盘间动态调度)

**虚拟存储技术**
> 虚拟内存：用到的从外存调入内存，不够用时，不用的调到外存
> 
> 虚拟内存有一下三个主要特征:
> 
> 多次性:无需在作业运行时- .次性全部装入内存，而是允许被分成多次调入内存。
> 
> 对换性:在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。
> 
> 虚拟性:从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。

> 请求分页存储管理:
> 
> 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。
> <div align="center"><img src="figure\请求页表.png" width=80%/></div>
> 
> **最佳置换算法**：
> <div align="center"><img src="figure\最佳置换算法.png" width=%/></div>
> 
> **先进先出置换算法**：
> 
> 最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到.的是哪个页面。操作系统无法提前预判页面访问序列。因此，**最佳置换算法是无法实现的**。
>
> <div align="center"><img src="figure\先进先出置换算法.png" width=%/></div>
> 
> **最近许久未使用算法**：
> <div align="center"><img src="figure\最近许久未使用.png" width=%/></div>
>
> **时钟置换算法（CLOCK）**
> <div align="center"><img src="figure\Clock.png" width=%/></div>
> 
> 改进型时钟：
> <div align="center"><img src="figure\改进型时钟.png" width=%/></div>

**页面分配策略**
>  **驻留集**:指请求分页存储管理中**给进程分配的物理块的集合**。在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。若驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少;驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大小。
> 
> **固定分配**:操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。即，驻留集大小不变
> 
> **可变分配**:先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即，驻留集大小可变
> 
> **局部置换**:发生缺页时只能选进程自己的物理块进行置换。
> 
> **全局置换**:可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程。

> **固定分配局部置换**:系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。
> 
> 这种策略的**缺点**是:很难在刚开始就确定应为每个进程分配多少个物理块才算合理。(采用这种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为一个进程分配的内存块数)
> 
> **可变分配全局置换**:刚开始会为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程;若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程。采用这种策略时，只要某进程发生缺页，都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加。
> 
> **可变分配局部置换**:刚开始会为每个进程分配一-定 数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度;反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。
> 
> 可变分配全局置换:**只要缺页就给分配新物理块**
> 
> 可变分配局部置换:**要根据发生缺页的频率来动态地增加或减少进程的物理块**

> 刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为**抖动**，或**颠簸**。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)






#### 3.1.9 两级页表

#### 3.1.10

## 四、文件管理

### 4.1 文件
**文件的属性**:
> **文件名**:由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件。
> 
> **标识符**: 一个系统内的各文件标识符唯一，对用户来说毫无可读性，因此标识符只是操作系统用于区分各个文件的一种内部名称。
> 
> **类型**:指明文件的类型
> 
> **位置**:文件存放的路径(让用户使用)、在外存中的地址(操作系统使用，对用户不可见)
> 
> **大小**:指明文件大小
> 
> **创建时间、上次修改时间、文件所有者信息**
> 
> **保护信息**:对文件进行保护的访问控制信息

#### 4.1.1 文件的逻辑结构
**无结构文件**:文件内部的数据就是一系列二进制流或字符流组成。又称“流式文件”。如:Windows操作系统中的.txt 文件。

**有结构文件**:由一-组相似的记录组成，又称“记录式文件”。每条记录又若千个数据项组成。如:数据库表文件。一般来说，每条记录有一个数据项可作为关键字。根据各条记录的长度(占用的存储空间)是否相等，又可分为定长记录和可变长记录两种。

> **有结构文件的逻辑结构**：
> **顺序文件**:文件中的记录一个接-一个地顺序排列(逻辑上)，记录可以是定长的或可变长的。各个记录在物理，上可以顺序存储或链式存储。
>
> 串结构 **->** 记录之间的顺序与关键字无关
> 顺序结构 **->** 记录之间的顺序按关键字顺序排列

> **索引文件**：索引表本身是定长记录的顺序文件。因此可以快速找到第i个记录对应的索引项。可将关键字作为索引号内容，若按关键字顺序排列，则还可以支持按照关键字折半查找。每当要增加/删除-一个记录时，需要对索引表进行修改。由于索引文件有很快的检索速度，因此主要用于对信息处理的及时性要求比较高的场合。

> **索引顺序文件**：索引文件和顺序文件思想的结合。索引顺序文件中，同样会为文件建立张索引表，但不同的是:并不是每个记录对应一个索引表项，而是一组记录对应一个索引表项。

> **多级索引文件**：为了进一步提高检索效率，可以为顺序文件建立**多级索引表**。例如，对于一个含106个记录的文件，可先为该文件建立一张低级索引表，每100个记录为一组，故低级索引表中共有10000个表项(即10000个定长记录)，再把这10000个定长记录分组，每组100个，为其建立顶级索引表，故顶级索引表中共有100个表

#### 4.1.2 文件目录
**文件控制块**：**FCB**的有序集合称为“文件目录”，一个FCB就是一个文件目录项。

FCB中包含了文件的基本信息(文件名、物理地址、逻辑结构、物理结构等)，存取控制信息( 是否可读/可写、禁止访问的用户名.单等)，使用信息(如文件的建立时间、修改时间等)

最重要，最基本的还是文件名、文件存放的物理地址。

>**单级目录项**：早期操作系统并不支持多级目录，整个系统中只建立一张目录表，每个文件占一个目录项。

> **两级目录项**：早期的多用户操作系统，采用两级目录结构。分为主文件目录(MFD，Master File Directory)和用户文件目录(UFD，User Flie Directory)。

> **多级目录项**：window现用的
> 
> 树形目录结构可以很方便地对文件进行分类，层次结构清晰，也能够更有效地进行文件的管理和保护。但是，树形结构不便于实现文件的共享。为此，提出了“ **无环图目录结构**”。
>
>在树形目录结构的基础上，**增加些指向同一节点的有向边**，使整个目录成为一个**有向无环图**可以更方便地实现多个用户间的文件共享。


#### 4.1.3 文件的物理结构

在内存管理中，进程的逻辑地址空间被分为一个一个页面。同样的，在外存管理中，为了方便对文件数据的管理，**文件的逻辑地址空间也被分为了一个一个的文件“块”**，于是文件的逻辑地址也可以表示为 **(逻辑块号，块内地址)** 的形式。

> **连续分配**：连续分配方式要求每个文件在磁盘上占有一组连续的块。
> 
> **优点**:支持顺序访问和直接访问(即随机访问);连续分配的文件在顺序访问时速度最快
>
> **缺点**:不方便文件拓展;存储空间利用率低，会产生磁盘碎片

> **链接分配**：**链接分配采取离散分配的方式，可以为文件分配离散的磁盘块。** 分为隐式链接和显式链接两种。
>
>**隐式链接**——除文件的最后一个盘块之外，每个盘块中都存有指向下一个盘块的指针。文件目录包括文件第一块的指针和最后一块的指针。
>
>>优点:很方便文件拓展，不会有碎片问题，外存利用率高。
>
>>缺点:只支持顺序访问，不支持随机访问，查找效率低，指向下一个盘块的指针也需要耗费少量的存储空间。
>
>**显式链接**——把用于链接文件各物理块的指针显式地存放在一-张表中， 即文件分配表(FAT， File Allocation Table)。一个磁盘只会建立一张文件分配表。开机时文件分配表放入内存，并常驻内存。
>
>>优点:很方便文件拓展，不会有碎片问题，外存利用率高，并且支持随机访问。相比于隐式链接来说，地址转换时不需要访问磁盘，因此文件的访问效率更高。
>
>>缺点:文件分配表的需要占用一定的存储空间。
>
> **索引分配**：
> 索引分配允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块(索引表的功能类似于内存管理中的页表一建立逻辑页面到物理页之间的映射关系)。索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块。
> 
>若文件太大，索引表项太多，可以采取以下三种方法解决:
>>**①链接方案**:如果索引表太大，一个索引块装不下，那么可以将多个索引块链接起来存放。**缺点**:若文件很大，索引表很长，就需要将很多个索引块链接起来。想要找到i号索引块，必须先依次读入0~i-1号索引块，这就导致磁盘I/O次数过多，查找效率低下。
>>
>>**②多层索引**:建立多层索引(**原理类似于多级页表**)。使第一层索引块指向第二层的索引块。还可根据文件大小的要求再建立第三层、第四层索引块。采用K层索引结构，且**顶级索引表未调入内存**，则访问一个数据块只需要K+ 1次读磁盘操作。**缺点**:即使是小文件，访问一个数据块依然需要K+1次读磁盘。
>>
>>**③混合索引**:多种索引分配方式的结合。例如，一个文件的顶级索引表中，既包含**直接地址索引**(直接指向数据块)，又包含**一级间接索引**(指向单层索引表)、还包含**两级间接索引**(指向两层索引表)。**优点**:对于小文件来说，访问一个数据块所需的读磁盘次数更少。
>>**超级超级超级重点**:**①**要会根据多层索引、混合索引的结构计算出文件的最大长度(**Key**: 各级索引表最大不能超过一个块) ;**②**要能自己分析访问某个数据块所需要的读磁盘次数(**Key**: FCB中 会存有指向顶级索引块的指针，因此可以根据FCB读入顶级索引块。每次读入下一级的索引块都需要一次读磁盘操作。另外，要注意题目条件——顶级索引块是否已调入内存)


#### 4.1.4 文件存储空间管理
空闲表法、空闲链表法、位示图法、成组链接法

#### 4.1.5 文件共享 
基于索引结点的共享方式(硬链接)
基于符号链的共享方式(软链接)——快捷方式

#### 4.1.6 文件保护
**口令保护**：为文件设置一个“口令”(如: abc112233) ，用户请求访问该文件时必须提供“口令”。
>优点:保存口令的空间开销不多，验证口令的时间开销也很小。

>缺点:正确的“口令”存放在系统内部，不够安全。

**加密保护**：使用某个“密码”对文件进行加密，在访问文件时需要提供正确的“密码”才能对文件进行正确的解密。
>优点:保密性强，不需要在系统中存储“密码”
>
>缺点:编码/译码，或者说加密/解密要花费一定时间。

**访问控制**：在每个文件的FCB (或索引结点)中增加一个访问控制列表(Access-Control List, ACL)，该表中记录了各个用户可以对该文件执行哪些操作。

#### 4.1.7 文件系统层次结构
<div align="center"><img src="figure\层次结构.png" width=%/></div>

## 五、输入/输出（I/O）管理

### 5.1 I/O设备

**按特性分类**：人机交互类外部设备、存储设备、网络通信设备

**按信息交换的单位分类**：块设备、字符设备

**I/O设备**包括机械部件、电子部件（I/O控制器、设备控制器）

**I/O控制器**：CPU可控制I/O控制器，又由I/O控制器来控制设备的机械部件，CPU和机械部件的“中介”
> **接受和识别CPU发出的命令**
> >如CPU发来的read/write命令，I/O控制器中会有相应的**控制寄存器**来存放命令和参数
>
> **向CPU报告设备的状态**
> > /O控制器中会有相应的状态寄存器，用于记录I/O设备的当前状态。如:1表示空闲，0表示忙碌
>
> **数据交换**
> >I/O控制器中会设置相应的**数据寄存器**。输出时，数据寄存器用于暂存CPU发来的数据，之后再由控制器传送设备。输入时，数据寄存器用于暂存设备发来的数据，之后CPU从数据寄存器中取走数据。
>
> **地址识别**
>>类似于内存的地址，为了区分设备控制器中的各个寄存器，也需要给各个寄存器设置一个特定的“地址”。/0控制器通过CPU提供的“地址”来判断CPU要读/写的是哪个寄存器


### 5.2 I/O控制方式
**程序直接控制方式**
完成一次读/写操作（轮询）
<div align="center"><img src="figure\cpu.png" width=%/></div>

>**优点**:实现简单。在读/写指令之后，加上实现循环检查的系列指令即可(因此才称为“程序直接控制方式”)
>
>**缺点**: CPU和I/O设备只能串行工作，CPU需要一直轮询检查,长期处于“忙等”状态，CPU利用率低。

**中断驱动方式**
> 引入**中断机制**。由于I/O设备速度很慢，因此在CPU发出读/写命令后，**可将等待I/O的进程阻塞**，先切换到别的进程执行。当I/0完成后，控制器会向CPU发出一个中断信号，CPU**检测到中断信号后**，会保存当前进程的运行环境信息，转去执行中断处理程序处理该中断。处理中断的过程中，CPU从I/O控制器读一个字的数据传送到CPU寄存器，再写入主存。接着，**CPU恢复等待I/O的进程(或其他进程)的运行环境，然后继续执行。**

>**注意**:
>
> ①CPU会在每个指令周期的末尾检查中断;
> 
> ②中断处理过程中需要保存、恢复进程的运行环境,这个过程是需要一定时间开销的。可见，如果中断发生的频率太高，也会降低系统性能。
<div align="center"><img src="figure\中断.png" width=%/></div>


> **优点**:与“程序直接控制方式”相比，在“中断驱动方式”中，I/O控制器会通过中断信号主动报告I/0已完成，CPU不再需要不停地轮询。CPU和/O设备可并行工作，CPU利用率得到明显提升。
>
> **缺点**:每个字在I/0设备与内存之间的传输，都需要经过CPU。而频繁的中断处理会消耗较多的CPU时间。


**DMA方式**
与“中断驱动方式”相比，DMA方式( Direct Memory Access，直接存储器存取。主要用于块设备的I/0控制)有这样几个改进:

① 数据的传送单位是“块”。不再是一个字、一个字的传送;

② 数据的流向是从设备直接放入内存，或者从内存直接到设备。不再需要CPU作为“快递小哥”。

③ 仅在传送一个或多个数据块的开始和结束时，才需要CPU干预。

> **优点**:数据传输以“块”为单位，CPU介入频率进一步降低。数据的传输不再需要先经过CPU再写入内存，数据传输效率进一步增加。CPU和I/O设 备的并行性得到提升。
>
> **缺点**: CPU每发出一条I/O指令，只能读/写一个或多个连续的数据块。如果要读/写多个离散存储的数据块，或者要将数据分别写到不同的内存区域时，CPU要分别发出多条I/O指令，进行多次中断处理才能完成。


**通道控制方式**

**通道**:一种硬件，可以理解为是“ 弱鸡版的CPU”。通道可以识别并执行一系列通道指令

通道执行通道指令，随后CPU通过中断完成最终操作

> **缺点**:实现复杂，需要专门的通道硬件支持
> 
> **优点**: CPU、通道，I/0设备可并行工作，资源利用率很高。


<div align="center"><img src="figure\IO层次.png" width=%/></div>

### 5.3 假脱机技术

<div align="center"><img src="figure\假脱机技术.png" width=%/></div>

